# Chapter III Fundamentals of Deep Learning

### What is neural network?

### What is perception machine? What is multi-layer perception machine, a.k.a MLP?

### What are the common used neural networks?

![commonly-used-neural-networks](http://www.asimovinstitute.org/wp-content/uploads/2016/09/neuralnetworks.png)

For more information, please visit [asimov institute](http://www.asimovinstitute.org/neural-network-zoo/)

### There are so many deep learning frameworks, which one should I choose?

### Why we need deep neural networks? What is it?

### Why it is so hard to train a deep neural network?

### What are the differences between machine learning and deep learning?

### What is forward propagation and backward propagation? a.k.a FP and BP?

### Still unclear, more examples?

### How to calculate the output of a neural network?

### What is hyper parameters?

### How to find the best value for hyper parameters?

### Generally, what are the steps to find a hyper parameters?

### What is activation function? Why we need it?

### What are the commonly used activation functions?

sigmoid, tanh, Relu, Leaky Relu, softplus and softmax are some commonly used activation functions.

### What is the derivatives of those activation functions?

### What properties do these activation functions have?

### How to choose an proper activation function?

### What are the advantages of Relu? Why it is so popular?

### Why softmax can be used to do multi class classification?

### Why tanh has a higher convergence rate?

### What is batch size? Why we need it?

### What is normalization? Why we need it?

### What is batch normalization? Why we need it?

### What is fine tuning?

### 